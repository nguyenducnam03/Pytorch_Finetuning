{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10749581,"sourceType":"datasetVersion","datasetId":6666875},{"sourceId":222521111,"sourceType":"kernelVersion"}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import - dataset","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install torch transformers datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:42:24.021225Z","iopub.execute_input":"2025-02-14T14:42:24.021427Z","iopub.status.idle":"2025-02-14T14:42:28.395701Z","shell.execute_reply.started":"2025-02-14T14:42:24.021407Z","shell.execute_reply":"2025-02-14T14:42:28.394742Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\n\n# Load GPT-2 model and tokenizer\nmodel_name = \"gpt2\"  # Can use \"gpt2-medium\", \"gpt2-large\", \"gpt-j-6b\" etc.\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:42:28.396584Z","iopub.execute_input":"2025-02-14T14:42:28.396882Z","iopub.status.idle":"2025-02-14T14:42:53.027940Z","shell.execute_reply.started":"2025-02-14T14:42:28.396855Z","shell.execute_reply":"2025-02-14T14:42:53.027280Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e70e4d924a149bbab51924da739039f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e179d4f37c049aba8fb035966b5774a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e260cdaa98a4492cbaeffb747dfa942c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f0dae54a19c47f1871cb626c8141e81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cde6a310eb894feba9170e5d5537fafc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a20bccb97cd4ade8db965e986cbfd6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da6078ebeeca46358160cf82081ba093"}},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"## Inference first","metadata":{}},{"cell_type":"code","source":"inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n# Generate text\noutputs = model.generate(**inputs, max_length=50, num_return_sequences=1)\noutputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:44:07.803908Z","iopub.execute_input":"2025-02-14T14:44:07.804310Z","iopub.status.idle":"2025-02-14T14:44:09.248175Z","shell.execute_reply.started":"2025-02-14T14:44:07.804277Z","shell.execute_reply":"2025-02-14T14:44:09.247401Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"tensor([[15496,    11,   616,  3290,   318, 13779,    13,   314,  1101,   407,\n          1654,   611,   673,   338,   257, 26188,   393,   407,    13,   314,\n          1101,   407,  1654,   611,   673,   338,   257,  3290,   393,   407,\n            13,   314,  1101,   407,  1654,   611,   673,   338,   257,  3290,\n           393,   407,    13,   198,   198,    40,  1101,   407,  1654,   611]])"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Decode and print result\ngenerated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(generated_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:44:18.779506Z","iopub.execute_input":"2025-02-14T14:44:18.779825Z","iopub.status.idle":"2025-02-14T14:44:18.785815Z","shell.execute_reply.started":"2025-02-14T14:44:18.779797Z","shell.execute_reply":"2025-02-14T14:44:18.785028Z"}},"outputs":[{"name":"stdout","text":"Hello, my dog is cute. I'm not sure if she's a puppy or not. I'm not sure if she's a dog or not. I'm not sure if she's a dog or not.\n\nI'm not sure if\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def generate_gpt2(sentence, max_length=100,device = \"cuda\"):\n    inputs = tokenizer(sentence, return_tensors=\"pt\").to(device)\n    model.to(device)\n    # Generate text\n    outputs = model.generate(**inputs, max_length=max_length, num_return_sequences=1)\n    # Decode\n    # Decode and print result\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return generated_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:45:47.918025Z","iopub.execute_input":"2025-02-14T14:45:47.918347Z","iopub.status.idle":"2025-02-14T14:45:47.922932Z","shell.execute_reply.started":"2025-02-14T14:45:47.918322Z","shell.execute_reply":"2025-02-14T14:45:47.921973Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"generate_gpt2(\"Hello, my dog is cute\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:46:02.078592Z","iopub.execute_input":"2025-02-14T14:46:02.078867Z","iopub.status.idle":"2025-02-14T14:46:03.692401Z","shell.execute_reply.started":"2025-02-14T14:46:02.078847Z","shell.execute_reply":"2025-02-14T14:46:03.691604Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"\"Hello, my dog is cute. I'm not sure if she's a puppy or not. I'm not sure if she's a dog or not. I'm not sure if she's a dog or not.\\n\\nI'm not sure if she's a puppy or not. I'm not sure if she's a dog or not.\\n\\nI'm not sure if she's a puppy or not. I'm not sure if she's a dog or not.\\n\\nI'm not\""},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## Test print loss with model","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(\"/kaggle/input/pytorch-finetuning-gpt2/data.csv\")\ndata.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:47:22.999042Z","iopub.execute_input":"2025-02-14T14:47:22.999394Z","iopub.status.idle":"2025-02-14T14:47:23.016606Z","shell.execute_reply.started":"2025-02-14T14:47:22.999364Z","shell.execute_reply":"2025-02-14T14:47:23.015754Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                     Bad_Practices                     Good_Practices\n0  <table alt=header>Title</table>  <table alt='header'>Title</table>\n1                      <tr>Content                   <tr>Content</tr>","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Bad_Practices</th>\n      <th>Good_Practices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;table alt=header&gt;Title&lt;/table&gt;</td>\n      <td>&lt;table alt='header'&gt;Title&lt;/table&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;tr&gt;Content</td>\n      <td>&lt;tr&gt;Content&lt;/tr&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"bad_1 = data.iloc[0,0]\ngood_1 = data.iloc[0,1]\nbad_1, good_1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:47:54.757968Z","iopub.execute_input":"2025-02-14T14:47:54.758299Z","iopub.status.idle":"2025-02-14T14:47:54.763689Z","shell.execute_reply.started":"2025-02-14T14:47:54.758273Z","shell.execute_reply":"2025-02-14T14:47:54.762955Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"('<table alt=header>Title</table>', \"<table alt='header'>Title</table>\")"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"import torch\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:49:53.688899Z","iopub.execute_input":"2025-02-14T14:49:53.689368Z","iopub.status.idle":"2025-02-14T14:49:53.694015Z","shell.execute_reply.started":"2025-02-14T14:49:53.689332Z","shell.execute_reply":"2025-02-14T14:49:53.692990Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"input_ids_bad = tokenizer.encode(bad_1, return_tensors=\"pt\")\ninput_ids_good = tokenizer.encode(good_1, return_tensors=\"pt\")\n# model(input_ids=input_ids_bad.to(device), labels=input_ids_good.to(device))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:49:57.696645Z","iopub.execute_input":"2025-02-14T14:49:57.696920Z","iopub.status.idle":"2025-02-14T14:49:57.702496Z","shell.execute_reply.started":"2025-02-14T14:49:57.696899Z","shell.execute_reply":"2025-02-14T14:49:57.701472Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## Create dataset English - Germany","metadata":{}},{"cell_type":"code","source":"# convert df to DataDict\nfrom datasets import Dataset, DatasetDict\n\n\n# Convert to Hugging Face Dataset\ndataset = Dataset.from_pandas(data)\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:52:20.041649Z","iopub.execute_input":"2025-02-14T14:52:20.041964Z","iopub.status.idle":"2025-02-14T14:52:20.814061Z","shell.execute_reply.started":"2025-02-14T14:52:20.041943Z","shell.execute_reply":"2025-02-14T14:52:20.813401Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Bad_Practices', 'Good_Practices'],\n    num_rows: 6712\n})"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# Create a DatasetDict (you can split it into train/test/validation if needed)\ndataset_dict = DatasetDict({\n    \"train\": dataset.select(range(100)),\n    \"test\":dataset.select(range(100))\n})\n\n# Print dataset structure\nprint(dataset_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:56:49.434364Z","iopub.execute_input":"2025-02-14T14:56:49.434656Z","iopub.status.idle":"2025-02-14T14:56:49.442281Z","shell.execute_reply.started":"2025-02-14T14:56:49.434635Z","shell.execute_reply":"2025-02-14T14:56:49.441556Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['Bad_Practices', 'Good_Practices'],\n        num_rows: 100\n    })\n    test: Dataset({\n        features: ['Bad_Practices', 'Good_Practices'],\n        num_rows: 100\n    })\n})\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## Tokenizer","metadata":{}},{"cell_type":"code","source":"# Tokenization function\ndef tokenize_function(examples):\n    model_inputs = tokenizer(examples[\"Bad_Practices\"], padding=\"max_length\", truncation=True, max_length=100)\n    labels = tokenizer(examples[\"Good_Practices\"], padding=\"max_length\", truncation=True, max_length=100)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:56:51.001697Z","iopub.execute_input":"2025-02-14T14:56:51.001995Z","iopub.status.idle":"2025-02-14T14:56:51.006328Z","shell.execute_reply.started":"2025-02-14T14:56:51.001973Z","shell.execute_reply":"2025-02-14T14:56:51.005375Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Set the pad_token for the tokenizer\ntokenizer.pad_token = tokenizer.eos_token\n# Apply tokenization\ntokenized_datasets = dataset_dict.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:56:51.149014Z","iopub.execute_input":"2025-02-14T14:56:51.149304Z","iopub.status.idle":"2025-02-14T14:56:53.447027Z","shell.execute_reply.started":"2025-02-14T14:56:51.149281Z","shell.execute_reply":"2025-02-14T14:56:53.446200Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bce6f40cb1ce44cfb409cb62ed7a048c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7efe9fb271a34b8c88c1856e2812177a"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"tokenized_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:56:53.448057Z","iopub.execute_input":"2025-02-14T14:56:53.448296Z","iopub.status.idle":"2025-02-14T14:56:53.452920Z","shell.execute_reply.started":"2025-02-14T14:56:53.448275Z","shell.execute_reply":"2025-02-14T14:56:53.452179Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Bad_Practices', 'Good_Practices', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 100\n    })\n    test: Dataset({\n        features: ['Bad_Practices', 'Good_Practices', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 100\n    })\n})"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns(['Bad_Practices'])\ntokenized_datasets = tokenized_datasets.remove_columns(['Good_Practices'])\ntokenized_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:56:53.454390Z","iopub.execute_input":"2025-02-14T14:56:53.454661Z","iopub.status.idle":"2025-02-14T14:56:53.472792Z","shell.execute_reply.started":"2025-02-14T14:56:53.454632Z","shell.execute_reply":"2025-02-14T14:56:53.471966Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 100\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 100\n    })\n})"},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntokenized_datasets.set_format(\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:56:53.473751Z","iopub.execute_input":"2025-02-14T14:56:53.474028Z","iopub.status.idle":"2025-02-14T14:56:53.486792Z","shell.execute_reply.started":"2025-02-14T14:56:53.473999Z","shell.execute_reply":"2025-02-14T14:56:53.486080Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# Create dataloaders\ntrain_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=8, shuffle=True)\ntest_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=8, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:56:53.545215Z","iopub.execute_input":"2025-02-14T14:56:53.545450Z","iopub.status.idle":"2025-02-14T14:56:53.549467Z","shell.execute_reply.started":"2025-02-14T14:56:53.545431Z","shell.execute_reply":"2025-02-14T14:56:53.548605Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"from torch.optim import AdamW\noptimizer = AdamW(model.parameters(), lr=5e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:56:57.693655Z","iopub.execute_input":"2025-02-14T14:56:57.693976Z","iopub.status.idle":"2025-02-14T14:56:57.698661Z","shell.execute_reply.started":"2025-02-14T14:56:57.693949Z","shell.execute_reply":"2025-02-14T14:56:57.697774Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nmodel.to(device)\n\nepochs = 30  # Number of training epochs\n\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n\n    for batch in train_dataloader:\n        # Move batch to device\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        # Forward pass\n        outputs = model(**batch)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f\"Epoch {epoch+1} - Loss: {total_loss / len(train_dataloader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:57:14.231045Z","iopub.execute_input":"2025-02-14T14:57:14.231378Z","iopub.status.idle":"2025-02-14T14:58:05.978732Z","shell.execute_reply.started":"2025-02-14T14:57:14.231345Z","shell.execute_reply":"2025-02-14T14:58:05.977921Z"}},"outputs":[{"name":"stdout","text":"cuda\nEpoch 1 - Loss: 0.2811214465361375\nEpoch 2 - Loss: 0.23510802479890677\nEpoch 3 - Loss: 0.21153342494597802\nEpoch 4 - Loss: 0.194926639015858\nEpoch 5 - Loss: 0.17669604260187882\nEpoch 6 - Loss: 0.16691776766226843\nEpoch 7 - Loss: 0.15628014275660881\nEpoch 8 - Loss: 0.14997939536204705\nEpoch 9 - Loss: 0.134268031670497\nEpoch 10 - Loss: 0.13625521671313506\nEpoch 11 - Loss: 0.13161552009674218\nEpoch 12 - Loss: 0.13065327646640632\nEpoch 13 - Loss: 0.12390476923722488\nEpoch 14 - Loss: 0.12142727409417813\nEpoch 15 - Loss: 0.11999335541174962\nEpoch 16 - Loss: 0.12361065699503972\nEpoch 17 - Loss: 0.11714659573940131\nEpoch 18 - Loss: 0.11037066177679943\nEpoch 19 - Loss: 0.11250142409251286\nEpoch 20 - Loss: 0.10904796593464337\nEpoch 21 - Loss: 0.11188264076526348\nEpoch 22 - Loss: 0.10407132426133522\nEpoch 23 - Loss: 0.1107972780099282\nEpoch 24 - Loss: 0.1060666235593649\nEpoch 25 - Loss: 0.10425036515180881\nEpoch 26 - Loss: 0.10559802330457248\nEpoch 27 - Loss: 0.10096166340204385\nEpoch 28 - Loss: 0.1033548368857457\nEpoch 29 - Loss: 0.09902542714889233\nEpoch 30 - Loss: 0.09306271660786408\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"test = \"<table\"\ngenerate_gpt2(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T14:58:34.044876Z","iopub.execute_input":"2025-02-14T14:58:34.045210Z","iopub.status.idle":"2025-02-14T14:58:34.140963Z","shell.execute_reply.started":"2025-02-14T14:58:34.045174Z","shell.execute_reply":"2025-02-14T14:58:34.140310Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"\"<table style='description'>List Item</table>\""},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}